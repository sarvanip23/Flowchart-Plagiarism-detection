{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-Process the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(src):\n",
    "    gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    mask_1 = np.ones(src.shape[:2], dtype=\"uint8\") * 255\n",
    "    mask_2 = np.ones(src.shape[:2], dtype=\"uint8\") * 255\n",
    "    # noise = cv2.medianBlur(gray,3)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    cv2.imshow('Pre-Processed Image', thresh)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return thresh, mask_1, mask_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(masked):\n",
    "    pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "    config = (\"-l eng — oem 1 — psm 3\")\n",
    "    text = pytesseract.image_to_string(masked, config=config)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr(masked):\n",
    "    pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "    config = (\"-l eng — oem 1 — psm 3\")\n",
    "    # pytessercat\n",
    "    text = pytesseract.image_to_string(masked, config=config)\n",
    "    return text\n",
    "def remove_shapes(src, thresh, mask_1, mask_2):\n",
    "    list1 = []\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE,\n",
    "                                cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 400:\n",
    "            approx = cv2.approxPolyDP(cnt,\n",
    "                                      0.01 * cv2.arcLength(cnt, True), True)\n",
    "            cv2.drawContours(mask_1, [approx], -1, 0, 5)\n",
    "            if area < 50000:\n",
    "                if (len(approx) == 4):\n",
    "                    list1.append(\"square\")\n",
    "                    print(\"Square\")\n",
    "                else:\n",
    "                    list1.append(\"circle\")\n",
    "                    print(\"Circle\")\n",
    "                cv2.drawContours(mask_2, [approx], -1, 0, 5)\n",
    "                cv2.imshow('Masked Image', mask_2)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "    masked = cv2.bitwise_not(src, src, mask=mask_1)\n",
    "    masked = cv2.bitwise_or(src, src, mask=mask_1)\n",
    "    masked = cv2.bitwise_and(src, src, mask=mask_1)\n",
    "    cv2.imshow('Masked Image', masked)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    pre_prompt = \"Take the following two sets of strings as input, \\\n",
    "        which are extracted from two different flowcharts, \\\n",
    "        understand what the flowcharts are doing, \\\n",
    "        and \\\"only\\\" give a percentage of similarity between the two \\\n",
    "        as a response and nothing else, no explanation is required.\"\n",
    "    client = OpenAI(\n",
    "        api_key=\"INSERT KEY HERE\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"system\", \"content\": pre_prompt}, {\"role\": \"user\", \"content\": text}],\n",
    "    )\n",
    "    # return response.choices[0].message.content\n",
    "    return \"ok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src1 = cv2.imread(\n",
    "    r\"D:\\OneDrive\\Repositories\\Flowchart-Plagarism-Detector\\Dataset\\IMG-20231113-WA0047.jpg\")\n",
    "cv2.imshow('Original Image', src1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "thresh1, mask1_1, mask1_2 = pre_process(src1)\n",
    "masked1 = remove_shapes(src1, thresh1, mask1_1, mask1_2)\n",
    "text1 = \"1.\\n\"+ocr(masked1)+\"\\n\\n\"\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------\")\n",
    "\n",
    "src2 = cv2.imread(\n",
    "    r\"D:\\OneDrive\\Repositories\\Flowchart-Plagarism-Detector\\Dataset\\IMG-20231113-WA0048.jpg\")\n",
    "cv2.imshow('Original Image', src2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "thresh2, mask2_1, mask2_2 = pre_process(src2)\n",
    "masked2= remove_shapes(src2, thresh2, mask2_1, mask2_2)\n",
    "text2 = \"2. \\n\"+ocr(masked2)\n",
    "# print(text1+text2)\n",
    "print(predict(text1+text2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
